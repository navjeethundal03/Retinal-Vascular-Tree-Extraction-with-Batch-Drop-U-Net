{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "APY3daNuXOap",
        "outputId": "48813afe-f46b-45e8-8718-6157754d5e62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  newb_data.zip\n",
            "   creating: newb_data/test/\n",
            "   creating: newb_data/test/image/\n",
            "  inflating: newb_data/test/image/01_test_0.png  \n",
            "  inflating: newb_data/test/image/02_test_0.png  \n",
            "  inflating: newb_data/test/image/03_test_0.png  \n",
            "  inflating: newb_data/test/image/04_test_0.png  \n",
            "  inflating: newb_data/test/image/05_test_0.png  \n",
            "  inflating: newb_data/test/image/06_test_0.png  \n",
            "  inflating: newb_data/test/image/07_test_0.png  \n",
            "  inflating: newb_data/test/image/08_test_0.png  \n",
            "  inflating: newb_data/test/image/09_test_0.png  \n",
            "  inflating: newb_data/test/image/10_test_0.png  \n",
            "   creating: newb_data/test/mask/\n",
            "  inflating: newb_data/test/mask/01_test_0.png  \n",
            "  inflating: newb_data/test/mask/02_test_0.png  \n",
            "  inflating: newb_data/test/mask/03_test_0.png  \n",
            "  inflating: newb_data/test/mask/04_test_0.png  \n",
            "  inflating: newb_data/test/mask/05_test_0.png  \n",
            "  inflating: newb_data/test/mask/06_test_0.png  \n",
            "  inflating: newb_data/test/mask/07_test_0.png  \n",
            "  inflating: newb_data/test/mask/08_test_0.png  \n",
            "  inflating: newb_data/test/mask/09_test_0.png  \n",
            "  inflating: newb_data/test/mask/10_test_0.png  \n",
            "   creating: newb_data/train/\n",
            "   creating: newb_data/train/image/\n",
            "  inflating: newb_data/train/image/21_training_0.png  \n",
            "  inflating: newb_data/train/image/21_training_1.png  \n",
            "  inflating: newb_data/train/image/21_training_2.png  \n",
            "  inflating: newb_data/train/image/21_training_3.png  \n",
            "  inflating: newb_data/train/image/22_training_0.png  \n",
            "  inflating: newb_data/train/image/22_training_1.png  \n",
            "  inflating: newb_data/train/image/22_training_2.png  \n",
            "  inflating: newb_data/train/image/22_training_3.png  \n",
            "  inflating: newb_data/train/image/23_training_0.png  \n",
            "  inflating: newb_data/train/image/23_training_1.png  \n",
            "  inflating: newb_data/train/image/23_training_2.png  \n",
            "  inflating: newb_data/train/image/23_training_3.png  \n",
            "  inflating: newb_data/train/image/24_training_0.png  \n",
            "  inflating: newb_data/train/image/24_training_1.png  \n",
            "  inflating: newb_data/train/image/24_training_2.png  \n",
            "  inflating: newb_data/train/image/24_training_3.png  \n",
            "  inflating: newb_data/train/image/25_training_0.png  \n",
            "  inflating: newb_data/train/image/25_training_1.png  \n",
            "  inflating: newb_data/train/image/25_training_2.png  \n",
            "  inflating: newb_data/train/image/25_training_3.png  \n",
            "  inflating: newb_data/train/image/26_training_0.png  \n",
            "  inflating: newb_data/train/image/26_training_1.png  \n",
            "  inflating: newb_data/train/image/26_training_2.png  \n",
            "  inflating: newb_data/train/image/26_training_3.png  \n",
            "  inflating: newb_data/train/image/27_training_0.png  \n",
            "  inflating: newb_data/train/image/27_training_1.png  \n",
            "  inflating: newb_data/train/image/27_training_2.png  \n",
            "  inflating: newb_data/train/image/27_training_3.png  \n",
            "  inflating: newb_data/train/image/28_training_0.png  \n",
            "  inflating: newb_data/train/image/28_training_1.png  \n",
            "  inflating: newb_data/train/image/28_training_2.png  \n",
            "  inflating: newb_data/train/image/28_training_3.png  \n",
            "  inflating: newb_data/train/image/29_training_0.png  \n",
            "  inflating: newb_data/train/image/29_training_1.png  \n",
            "  inflating: newb_data/train/image/29_training_2.png  \n",
            "  inflating: newb_data/train/image/29_training_3.png  \n",
            "  inflating: newb_data/train/image/30_training_0.png  \n",
            "  inflating: newb_data/train/image/30_training_1.png  \n",
            "  inflating: newb_data/train/image/30_training_2.png  \n",
            "  inflating: newb_data/train/image/30_training_3.png  \n",
            "  inflating: newb_data/train/image/31_training_0.png  \n",
            "  inflating: newb_data/train/image/31_training_1.png  \n",
            "  inflating: newb_data/train/image/31_training_2.png  \n",
            "  inflating: newb_data/train/image/31_training_3.png  \n",
            "  inflating: newb_data/train/image/32_training_0.png  \n",
            "  inflating: newb_data/train/image/32_training_1.png  \n",
            "  inflating: newb_data/train/image/32_training_2.png  \n",
            "  inflating: newb_data/train/image/32_training_3.png  \n",
            "  inflating: newb_data/train/image/33_training_0.png  \n",
            "  inflating: newb_data/train/image/33_training_1.png  \n",
            "  inflating: newb_data/train/image/33_training_2.png  \n",
            "  inflating: newb_data/train/image/33_training_3.png  \n",
            "  inflating: newb_data/train/image/34_training_0.png  \n",
            "  inflating: newb_data/train/image/34_training_1.png  \n",
            "  inflating: newb_data/train/image/34_training_2.png  \n",
            "  inflating: newb_data/train/image/34_training_3.png  \n",
            "  inflating: newb_data/train/image/35_training_0.png  \n",
            "  inflating: newb_data/train/image/35_training_1.png  \n",
            "  inflating: newb_data/train/image/35_training_2.png  \n",
            "  inflating: newb_data/train/image/35_training_3.png  \n",
            "  inflating: newb_data/train/image/36_training_0.png  \n",
            "  inflating: newb_data/train/image/36_training_1.png  \n",
            "  inflating: newb_data/train/image/36_training_2.png  \n",
            "  inflating: newb_data/train/image/36_training_3.png  \n",
            "  inflating: newb_data/train/image/37_training_0.png  \n",
            "  inflating: newb_data/train/image/37_training_1.png  \n",
            "  inflating: newb_data/train/image/37_training_2.png  \n",
            "  inflating: newb_data/train/image/37_training_3.png  \n",
            "  inflating: newb_data/train/image/38_training_0.png  \n",
            "  inflating: newb_data/train/image/38_training_1.png  \n",
            "  inflating: newb_data/train/image/38_training_2.png  \n",
            "  inflating: newb_data/train/image/38_training_3.png  \n",
            "  inflating: newb_data/train/image/39_training_0.png  \n",
            "  inflating: newb_data/train/image/39_training_1.png  \n",
            "  inflating: newb_data/train/image/39_training_2.png  \n",
            "  inflating: newb_data/train/image/39_training_3.png  \n",
            "  inflating: newb_data/train/image/40_training_0.png  \n",
            "  inflating: newb_data/train/image/40_training_1.png  \n",
            "  inflating: newb_data/train/image/40_training_2.png  \n",
            "  inflating: newb_data/train/image/40_training_3.png  \n",
            "  inflating: newb_data/train/image/41_training_0.png  \n",
            "  inflating: newb_data/train/image/41_training_1.png  \n",
            "  inflating: newb_data/train/image/41_training_2.png  \n",
            "  inflating: newb_data/train/image/41_training_3.png  \n",
            "  inflating: newb_data/train/image/42_training_0.png  \n",
            "  inflating: newb_data/train/image/42_training_1.png  \n",
            "  inflating: newb_data/train/image/42_training_2.png  \n",
            "  inflating: newb_data/train/image/42_training_3.png  \n",
            "  inflating: newb_data/train/image/43_training_0.png  \n",
            "  inflating: newb_data/train/image/43_training_1.png  \n",
            "  inflating: newb_data/train/image/43_training_2.png  \n",
            "  inflating: newb_data/train/image/43_training_3.png  \n",
            "  inflating: newb_data/train/image/44_training_0.png  \n",
            "  inflating: newb_data/train/image/44_training_1.png  \n",
            "  inflating: newb_data/train/image/44_training_2.png  \n",
            "  inflating: newb_data/train/image/44_training_3.png  \n",
            "  inflating: newb_data/train/image/45_training_0.png  \n",
            "  inflating: newb_data/train/image/45_training_1.png  \n",
            "  inflating: newb_data/train/image/45_training_2.png  \n",
            "  inflating: newb_data/train/image/45_training_3.png  \n",
            "  inflating: newb_data/train/image/46_training_0.png  \n",
            "  inflating: newb_data/train/image/46_training_1.png  \n",
            "  inflating: newb_data/train/image/46_training_2.png  \n",
            "  inflating: newb_data/train/image/46_training_3.png  \n",
            "  inflating: newb_data/train/image/47_training_0.png  \n",
            "  inflating: newb_data/train/image/47_training_1.png  \n",
            "  inflating: newb_data/train/image/47_training_2.png  \n",
            "  inflating: newb_data/train/image/47_training_3.png  \n",
            "  inflating: newb_data/train/image/48_training_0.png  \n",
            "  inflating: newb_data/train/image/48_training_1.png  \n",
            "  inflating: newb_data/train/image/48_training_2.png  \n",
            "  inflating: newb_data/train/image/48_training_3.png  \n",
            "  inflating: newb_data/train/image/49_training_0.png  \n",
            "  inflating: newb_data/train/image/49_training_1.png  \n",
            "  inflating: newb_data/train/image/49_training_2.png  \n",
            "  inflating: newb_data/train/image/49_training_3.png  \n",
            "  inflating: newb_data/train/image/50_training_0.png  \n",
            "  inflating: newb_data/train/image/50_training_1.png  \n",
            "  inflating: newb_data/train/image/50_training_2.png  \n",
            "  inflating: newb_data/train/image/50_training_3.png  \n",
            "   creating: newb_data/train/mask/\n",
            "  inflating: newb_data/train/mask/21_training_0.png  \n",
            "  inflating: newb_data/train/mask/21_training_1.png  \n",
            "  inflating: newb_data/train/mask/21_training_2.png  \n",
            "  inflating: newb_data/train/mask/21_training_3.png  \n",
            "  inflating: newb_data/train/mask/22_training_0.png  \n",
            "  inflating: newb_data/train/mask/22_training_1.png  \n",
            "  inflating: newb_data/train/mask/22_training_2.png  \n",
            "  inflating: newb_data/train/mask/22_training_3.png  \n",
            "  inflating: newb_data/train/mask/23_training_0.png  \n",
            "  inflating: newb_data/train/mask/23_training_1.png  \n",
            "  inflating: newb_data/train/mask/23_training_2.png  \n",
            "  inflating: newb_data/train/mask/23_training_3.png  \n",
            "  inflating: newb_data/train/mask/24_training_0.png  \n",
            "  inflating: newb_data/train/mask/24_training_1.png  \n",
            "  inflating: newb_data/train/mask/24_training_2.png  \n",
            "  inflating: newb_data/train/mask/24_training_3.png  \n",
            "  inflating: newb_data/train/mask/25_training_0.png  \n",
            "  inflating: newb_data/train/mask/25_training_1.png  \n",
            "  inflating: newb_data/train/mask/25_training_2.png  \n",
            "  inflating: newb_data/train/mask/25_training_3.png  \n",
            "  inflating: newb_data/train/mask/26_training_0.png  \n",
            "  inflating: newb_data/train/mask/26_training_1.png  \n",
            "  inflating: newb_data/train/mask/26_training_2.png  \n",
            "  inflating: newb_data/train/mask/26_training_3.png  \n",
            "  inflating: newb_data/train/mask/27_training_0.png  \n",
            "  inflating: newb_data/train/mask/27_training_1.png  \n",
            "  inflating: newb_data/train/mask/27_training_2.png  \n",
            "  inflating: newb_data/train/mask/27_training_3.png  \n",
            "  inflating: newb_data/train/mask/28_training_0.png  \n",
            "  inflating: newb_data/train/mask/28_training_1.png  \n",
            "  inflating: newb_data/train/mask/28_training_2.png  \n",
            "  inflating: newb_data/train/mask/28_training_3.png  \n",
            "  inflating: newb_data/train/mask/29_training_0.png  \n",
            "  inflating: newb_data/train/mask/29_training_1.png  \n",
            "  inflating: newb_data/train/mask/29_training_2.png  \n",
            "  inflating: newb_data/train/mask/29_training_3.png  \n",
            "  inflating: newb_data/train/mask/30_training_0.png  \n",
            "  inflating: newb_data/train/mask/30_training_1.png  \n",
            "  inflating: newb_data/train/mask/30_training_2.png  \n",
            "  inflating: newb_data/train/mask/30_training_3.png  \n",
            "  inflating: newb_data/train/mask/31_training_0.png  \n",
            "  inflating: newb_data/train/mask/31_training_1.png  \n",
            "  inflating: newb_data/train/mask/31_training_2.png  \n",
            "  inflating: newb_data/train/mask/31_training_3.png  \n",
            "  inflating: newb_data/train/mask/32_training_0.png  \n",
            "  inflating: newb_data/train/mask/32_training_1.png  \n",
            "  inflating: newb_data/train/mask/32_training_2.png  \n",
            "  inflating: newb_data/train/mask/32_training_3.png  \n",
            "  inflating: newb_data/train/mask/33_training_0.png  \n",
            "  inflating: newb_data/train/mask/33_training_1.png  \n",
            "  inflating: newb_data/train/mask/33_training_2.png  \n",
            "  inflating: newb_data/train/mask/33_training_3.png  \n",
            "  inflating: newb_data/train/mask/34_training_0.png  \n",
            "  inflating: newb_data/train/mask/34_training_1.png  \n",
            "  inflating: newb_data/train/mask/34_training_2.png  \n",
            "  inflating: newb_data/train/mask/34_training_3.png  \n",
            "  inflating: newb_data/train/mask/35_training_0.png  \n",
            "  inflating: newb_data/train/mask/35_training_1.png  \n",
            "  inflating: newb_data/train/mask/35_training_2.png  \n",
            "  inflating: newb_data/train/mask/35_training_3.png  \n",
            "  inflating: newb_data/train/mask/36_training_0.png  \n",
            "  inflating: newb_data/train/mask/36_training_1.png  \n",
            "  inflating: newb_data/train/mask/36_training_2.png  \n",
            "  inflating: newb_data/train/mask/36_training_3.png  \n",
            "  inflating: newb_data/train/mask/37_training_0.png  \n",
            "  inflating: newb_data/train/mask/37_training_1.png  \n",
            "  inflating: newb_data/train/mask/37_training_2.png  \n",
            "  inflating: newb_data/train/mask/37_training_3.png  \n",
            "  inflating: newb_data/train/mask/38_training_0.png  \n",
            "  inflating: newb_data/train/mask/38_training_1.png  \n",
            "  inflating: newb_data/train/mask/38_training_2.png  \n",
            "  inflating: newb_data/train/mask/38_training_3.png  \n",
            "  inflating: newb_data/train/mask/39_training_0.png  \n",
            "  inflating: newb_data/train/mask/39_training_1.png  \n",
            "  inflating: newb_data/train/mask/39_training_2.png  \n",
            "  inflating: newb_data/train/mask/39_training_3.png  \n",
            "  inflating: newb_data/train/mask/40_training_0.png  \n",
            "  inflating: newb_data/train/mask/40_training_1.png  \n",
            "  inflating: newb_data/train/mask/40_training_2.png  \n",
            "  inflating: newb_data/train/mask/40_training_3.png  \n",
            "  inflating: newb_data/train/mask/41_training_0.png  \n",
            "  inflating: newb_data/train/mask/41_training_1.png  \n",
            "  inflating: newb_data/train/mask/41_training_2.png  \n",
            "  inflating: newb_data/train/mask/41_training_3.png  \n",
            "  inflating: newb_data/train/mask/42_training_0.png  \n",
            "  inflating: newb_data/train/mask/42_training_1.png  \n",
            "  inflating: newb_data/train/mask/42_training_2.png  \n",
            "  inflating: newb_data/train/mask/42_training_3.png  \n",
            "  inflating: newb_data/train/mask/43_training_0.png  \n",
            "  inflating: newb_data/train/mask/43_training_1.png  \n",
            "  inflating: newb_data/train/mask/43_training_2.png  \n",
            "  inflating: newb_data/train/mask/43_training_3.png  \n",
            "  inflating: newb_data/train/mask/44_training_0.png  \n",
            "  inflating: newb_data/train/mask/44_training_1.png  \n",
            "  inflating: newb_data/train/mask/44_training_2.png  \n",
            "  inflating: newb_data/train/mask/44_training_3.png  \n",
            "  inflating: newb_data/train/mask/45_training_0.png  \n",
            "  inflating: newb_data/train/mask/45_training_1.png  \n",
            "  inflating: newb_data/train/mask/45_training_2.png  \n",
            "  inflating: newb_data/train/mask/45_training_3.png  \n",
            "  inflating: newb_data/train/mask/46_training_0.png  \n",
            "  inflating: newb_data/train/mask/46_training_1.png  \n",
            "  inflating: newb_data/train/mask/46_training_2.png  \n",
            "  inflating: newb_data/train/mask/46_training_3.png  \n",
            "  inflating: newb_data/train/mask/47_training_0.png  \n",
            "  inflating: newb_data/train/mask/47_training_1.png  \n",
            "  inflating: newb_data/train/mask/47_training_2.png  \n",
            "  inflating: newb_data/train/mask/47_training_3.png  \n",
            "  inflating: newb_data/train/mask/48_training_0.png  \n",
            "  inflating: newb_data/train/mask/48_training_1.png  \n",
            "  inflating: newb_data/train/mask/48_training_2.png  \n",
            "  inflating: newb_data/train/mask/48_training_3.png  \n",
            "  inflating: newb_data/train/mask/49_training_0.png  \n",
            "  inflating: newb_data/train/mask/49_training_1.png  \n",
            "  inflating: newb_data/train/mask/49_training_2.png  \n",
            "  inflating: newb_data/train/mask/49_training_3.png  \n",
            "  inflating: newb_data/train/mask/50_training_0.png  \n",
            "  inflating: newb_data/train/mask/50_training_1.png  \n",
            "  inflating: newb_data/train/mask/50_training_2.png  \n",
            "  inflating: newb_data/train/mask/50_training_3.png  \n"
          ]
        }
      ],
      "source": [
        "!unzip new_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n3zpzRaUWgP0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from glob import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "from operator import add\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score, roc_auc_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T1hRlp8JWgP4"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def train_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m0z157ydWgP6"
      },
      "outputs": [],
      "source": [
        "class DriveDataset(Dataset):\n",
        "    def __init__(self, images_path, masks_path):\n",
        "        self.images_path = images_path\n",
        "        self.masks_path = masks_path\n",
        "        self.n_samples = len(images_path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = cv2.imread(self.images_path[index], cv2.IMREAD_GRAYSCALE)\n",
        "        image = image/255.0\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "        image = image.astype(np.float32)\n",
        "        image = torch.from_numpy(image)\n",
        "\n",
        "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)\n",
        "        mask = mask/255.0\n",
        "        mask = np.expand_dims(mask, axis=0)\n",
        "        mask = mask.astype(np.float32)\n",
        "        mask = torch.from_numpy(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IT-Zif2iWgP7"
      },
      "outputs": [],
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Downs(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = Conv(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool2d((2, 2))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv(inputs)\n",
        "        p = self.pool(x)\n",
        "\n",
        "        return x, p\n",
        "\n",
        "class Ups(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2, padding=0)\n",
        "        self.conv = Conv(out_channels+out_channels, out_channels)\n",
        "\n",
        "    def forward(self, inputs, skip):\n",
        "        x = self.up(inputs)\n",
        "        x = torch.cat([x, skip], axis=1)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.down1 = Downs(1, 64)\n",
        "        self.down2 = Downs(64, 128)\n",
        "        self.down3 = Downs(128, 256)\n",
        "        self.down4 = Downs(256, 512)\n",
        "\n",
        "        self.bottleneck = Conv(512, 1024)\n",
        "\n",
        "        self.up1 = Ups(1024, 512)\n",
        "        self.up2 = Ups(512, 256)\n",
        "        self.up3 = Ups(256, 128)\n",
        "        self.up4 = Ups(128, 64)\n",
        "\n",
        "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        skip1, down1 = self.down1(inputs)\n",
        "        skip2, down2 = self.down2(down1)\n",
        "        skip3, down3 = self.down3(down2)\n",
        "        skip4, down4 = self.down4(down3)\n",
        "\n",
        "        b = self.bottleneck(down4)\n",
        "\n",
        "        up1 = self.up1(b, skip4)\n",
        "        up2 = self.up2(up1, skip3)\n",
        "        up3 = self.up3(up2, skip2)\n",
        "        up4 = self.up4(up3, skip1)\n",
        "\n",
        "        outputs = self.outputs(up4)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        inputs = torch.sigmoid(inputs)\n",
        "\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersect = (inputs * targets).sum()\n",
        "        dice = (2.*intersect + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "\n",
        "        return 1 - dice\n",
        "\n",
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        inputs = torch.sigmoid(inputs)\n",
        "\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersect = (inputs * targets).sum()\n",
        "        dice_loss = 1 - (2.*intersect + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        Dice_BCE = BCE + dice_loss\n",
        "\n",
        "        return Dice_BCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FjRvEEMAWgP9"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, loss_fn, device):\n",
        "    epoch_loss = 0.0\n",
        "    model.train()\n",
        "    for x,y in loader:\n",
        "        x = x.to(device, dtype = torch.float32)\n",
        "        y = y.to(device, dtype = torch.float32)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss = epoch_loss/len(loader)\n",
        "    return epoch_loss\n",
        "\n",
        "def evaluate(model, loader, loss_fn, device):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device, dtype=torch.float32)\n",
        "            y = y.to(device, dtype=torch.float32)\n",
        "\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        epoch_loss = epoch_loss/len(loader)\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "aQ0TyK7gWgQA",
        "outputId": "6b43d2c9-79d7-4a6e-b0d2-e8a572223a81"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss has improved from inf to 1.1830\n",
            "Epoch: 01 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 1.218\n",
            "\t Val. Loss: 1.183\n",
            "\n",
            "Validation loss has improved from 1.1830 to 0.9891\n",
            "Epoch: 02 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 1.045\n",
            "\t Val. Loss: 0.989\n",
            "\n",
            "Validation loss has improved from 0.9891 to 0.9343\n",
            "Epoch: 03 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.985\n",
            "\t Val. Loss: 0.934\n",
            "\n",
            "Validation loss has improved from 0.9343 to 0.8833\n",
            "Epoch: 04 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.934\n",
            "\t Val. Loss: 0.883\n",
            "\n",
            "Validation loss has improved from 0.8833 to 0.8428\n",
            "Epoch: 05 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.887\n",
            "\t Val. Loss: 0.843\n",
            "\n",
            "Validation loss has improved from 0.8428 to 0.7973\n",
            "Epoch: 06 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.843\n",
            "\t Val. Loss: 0.797\n",
            "\n",
            "Validation loss has improved from 0.7973 to 0.7584\n",
            "Epoch: 07 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.794\n",
            "\t Val. Loss: 0.758\n",
            "\n",
            "Validation loss has improved from 0.7584 to 0.7133\n",
            "Epoch: 08 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.752\n",
            "\t Val. Loss: 0.713\n",
            "\n",
            "Validation loss has improved from 0.7133 to 0.6599\n",
            "Epoch: 09 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.710\n",
            "\t Val. Loss: 0.660\n",
            "\n",
            "Validation loss has improved from 0.6599 to 0.6462\n",
            "Epoch: 10 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.674\n",
            "\t Val. Loss: 0.646\n",
            "\n",
            "Validation loss has improved from 0.6462 to 0.6159\n",
            "Epoch: 11 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.640\n",
            "\t Val. Loss: 0.616\n",
            "\n",
            "Validation loss has improved from 0.6159 to 0.5948\n",
            "Epoch: 12 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.609\n",
            "\t Val. Loss: 0.595\n",
            "\n",
            "Validation loss has improved from 0.5948 to 0.5584\n",
            "Epoch: 13 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.581\n",
            "\t Val. Loss: 0.558\n",
            "\n",
            "Validation loss has improved from 0.5584 to 0.5390\n",
            "Epoch: 14 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.552\n",
            "\t Val. Loss: 0.539\n",
            "\n",
            "Validation loss has improved from 0.5390 to 0.5260\n",
            "Epoch: 15 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.528\n",
            "\t Val. Loss: 0.526\n",
            "\n",
            "Validation loss has improved from 0.5260 to 0.4976\n",
            "Epoch: 16 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.505\n",
            "\t Val. Loss: 0.498\n",
            "\n",
            "Validation loss has improved from 0.4976 to 0.4858\n",
            "Epoch: 17 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.484\n",
            "\t Val. Loss: 0.486\n",
            "\n",
            "Validation loss has improved from 0.4858 to 0.4750\n",
            "Epoch: 18 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.467\n",
            "\t Val. Loss: 0.475\n",
            "\n",
            "Validation loss has improved from 0.4750 to 0.4616\n",
            "Epoch: 19 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.447\n",
            "\t Val. Loss: 0.462\n",
            "\n",
            "Validation loss has improved from 0.4616 to 0.4536\n",
            "Epoch: 20 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.429\n",
            "\t Val. Loss: 0.454\n",
            "\n",
            "Validation loss has improved from 0.4536 to 0.4361\n",
            "Epoch: 21 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.414\n",
            "\t Val. Loss: 0.436\n",
            "\n",
            "Validation loss has improved from 0.4361 to 0.4260\n",
            "Epoch: 22 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.399\n",
            "\t Val. Loss: 0.426\n",
            "\n",
            "Epoch: 23 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.385\n",
            "\t Val. Loss: 0.429\n",
            "\n",
            "Epoch: 24 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.370\n",
            "\t Val. Loss: 0.435\n",
            "\n",
            "Validation loss has improved from 0.4260 to 0.4104\n",
            "Epoch: 25 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.358\n",
            "\t Val. Loss: 0.410\n",
            "\n",
            "Epoch: 26 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.346\n",
            "\t Val. Loss: 0.439\n",
            "\n",
            "Validation loss has improved from 0.4104 to 0.4102\n",
            "Epoch: 27 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.331\n",
            "\t Val. Loss: 0.410\n",
            "\n",
            "Validation loss has improved from 0.4102 to 0.3972\n",
            "Epoch: 28 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.318\n",
            "\t Val. Loss: 0.397\n",
            "\n",
            "Validation loss has improved from 0.3972 to 0.3934\n",
            "Epoch: 29 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.308\n",
            "\t Val. Loss: 0.393\n",
            "\n",
            "Epoch: 30 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.295\n",
            "\t Val. Loss: 0.395\n",
            "\n",
            "Epoch: 31 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.284\n",
            "\t Val. Loss: 0.394\n",
            "\n",
            "Epoch: 32 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.275\n",
            "\t Val. Loss: 0.401\n",
            "\n",
            "Validation loss has improved from 0.3934 to 0.3925\n",
            "Epoch: 33 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.266\n",
            "\t Val. Loss: 0.392\n",
            "\n",
            "Validation loss has improved from 0.3925 to 0.3889\n",
            "Epoch: 34 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.259\n",
            "\t Val. Loss: 0.389\n",
            "\n",
            "Epoch: 35 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.253\n",
            "\t Val. Loss: 0.394\n",
            "\n",
            "Epoch: 36 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.246\n",
            "\t Val. Loss: 0.390\n",
            "\n",
            "Validation loss has improved from 0.3889 to 0.3800\n",
            "Epoch: 37 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.240\n",
            "\t Val. Loss: 0.380\n",
            "\n",
            "Epoch: 38 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.236\n",
            "\t Val. Loss: 0.405\n",
            "\n",
            "Epoch: 39 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.232\n",
            "\t Val. Loss: 0.393\n",
            "\n",
            "Epoch: 40 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.228\n",
            "\t Val. Loss: 0.385\n",
            "\n",
            "Epoch: 41 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.224\n",
            "\t Val. Loss: 0.389\n",
            "\n",
            "Epoch: 42 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.220\n",
            "\t Val. Loss: 0.388\n",
            "\n",
            "Epoch: 43 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.217\n",
            "\t Val. Loss: 0.386\n",
            "\n",
            "Epoch: 44 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.213\n",
            "\t Val. Loss: 0.382\n",
            "\n",
            "Epoch: 45 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.211\n",
            "\t Val. Loss: 0.389\n",
            "\n",
            "Epoch: 46 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.208\n",
            "\t Val. Loss: 0.382\n",
            "\n",
            "Epoch: 47 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.206\n",
            "\t Val. Loss: 0.380\n",
            "\n",
            "Validation loss has improved from 0.3800 to 0.3770\n",
            "Epoch: 48 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.204\n",
            "\t Val. Loss: 0.377\n",
            "\n",
            "Epoch: 49 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.203\n",
            "\t Val. Loss: 0.384\n",
            "\n",
            "Epoch: 50 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.201\n",
            "\t Val. Loss: 0.378\n",
            "\n",
            "Epoch: 51 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.200\n",
            "\t Val. Loss: 0.380\n",
            "\n",
            "Epoch: 52 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.198\n",
            "\t Val. Loss: 0.381\n",
            "\n",
            "Epoch: 53 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.195\n",
            "\t Val. Loss: 0.381\n",
            "\n",
            "Epoch: 54 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.193\n",
            "\t Val. Loss: 0.388\n",
            "\n",
            "Epoch: 55 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.191\n",
            "\t Val. Loss: 0.381\n",
            "\n",
            "Epoch: 56 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.190\n",
            "\t Val. Loss: 0.383\n",
            "\n",
            "Epoch: 57 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.188\n",
            "\t Val. Loss: 0.381\n",
            "\n",
            "Epoch: 58 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.187\n",
            "\t Val. Loss: 0.382\n",
            "\n",
            "Epoch: 59 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.186\n",
            "\t Val. Loss: 0.388\n",
            "\n",
            "Epoch: 60 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.185\n",
            "\t Val. Loss: 0.385\n",
            "\n",
            "Epoch: 61 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.184\n",
            "\t Val. Loss: 0.382\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-5f26c3c8ede3>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mloss_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-16206938aa95>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "set_seed(42)\n",
        "create_dir(\"files\")\n",
        "\n",
        "X_train = sorted(glob(r\"/content/new_data/train/image/*\"))\n",
        "y_train = sorted(glob(r\"/content/new_data/train/mask/*\"))\n",
        "\n",
        "X_val = sorted(glob(r\"/content/new_data/test/image/*\"))\n",
        "y_val = sorted(glob(r\"/content/new_data/test/mask/*\"))\n",
        "\n",
        "height = 512\n",
        "width = 512\n",
        "img_size = (height, width)\n",
        "batch_size = 2\n",
        "epochs = 30\n",
        "lr = 1e-4\n",
        "chkpt_path = \"files/checkpoint.pth\"\n",
        "\n",
        "train_data = DriveDataset(X_train, y_train)\n",
        "val_data = DriveDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset = train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset = val_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = UNET()\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "#lr_schedule = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
        "loss_fn = DiceBCELoss()\n",
        "\n",
        "best_loss = float(\"inf\")\n",
        "loss_dict = {'train':[],\n",
        "             'val':[]}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    start = time.time()\n",
        "    train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
        "    valid_loss = evaluate(model, val_loader, loss_fn, device)\n",
        "    loss_dict['train'].append(train_loss)\n",
        "    loss_dict['val'].append(valid_loss)\n",
        "\n",
        "    if valid_loss < best_loss:\n",
        "        hist = \"Validation loss has improved from {:2.4f} to {:2.4f}\".format(best_loss, valid_loss)\n",
        "        print(hist)\n",
        "        best_loss = valid_loss\n",
        "        torch.save(model.state_dict(), chkpt_path)\n",
        "\n",
        "    end = time.time()\n",
        "    epoch_mins, epoch_secs = train_time(start, end)\n",
        "    hist = f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\\n'\n",
        "    hist += f'\\tTrain Loss: {train_loss:.3f}\\n'\n",
        "    hist += f'\\t Val. Loss: {valid_loss:.3f}\\n'\n",
        "    print(hist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2b1mihsWgQC"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    \"\"\" Ground truth \"\"\"\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_true = y_true > 0.5\n",
        "    y_true = y_true.astype(np.uint8)\n",
        "    y_true = y_true.reshape(-1)\n",
        "\n",
        "    \"\"\" Prediction \"\"\"\n",
        "    y_pred = y_pred.cpu().numpy()\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.uint8)\n",
        "    y_pred = y_pred.reshape(-1)\n",
        "\n",
        "    score_jaccard = jaccard_score(y_true, y_pred)\n",
        "    score_f1 = f1_score(y_true, y_pred)\n",
        "    score_recall = recall_score(y_true, y_pred)\n",
        "    score_precision = precision_score(y_true, y_pred)\n",
        "    score_acc = accuracy_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "    return [score_jaccard, score_f1, score_recall, score_precision, score_acc, roc_auc]\n",
        "\n",
        "def mask_parse(mask):\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    mask = np.concatenate([mask, mask, mask], axis=-1)\n",
        "    return mask\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "create_dir(\"results\")\n",
        "\n",
        "test_x = sorted(glob(\"/content/new_data/test/image/*\"))\n",
        "test_y = sorted(glob(\"/content/new_data/test/mask/*\"))\n",
        "\n",
        "height = 512\n",
        "width = 512\n",
        "size = (height, width)\n",
        "checkpoint_path = \"files/checkpoint.pth\"\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = UNET()\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
        "time_taken = []\n",
        "\n",
        "for i, (img, msk) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
        "    name = img.split(\"/\")[-1].split(\".\")[0]\n",
        "    image = cv2.imread(img, cv2.IMREAD_GRAYSCALE) ## (512, 512, 3)\n",
        "    image = cv2.resize(image, size)\n",
        "    x = np.expand_dims(image, axis=0)      ## (3, 512, 512)\n",
        "    x = x/255.0\n",
        "    x = np.expand_dims(x, axis=0)           ## (1, 3, 512, 512)\n",
        "    x = x.astype(np.float32)\n",
        "    x = torch.from_numpy(x)\n",
        "    x = x.to(device)\n",
        "\n",
        "    mask = cv2.imread(msk, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = cv2.resize(mask, size)\n",
        "    y = np.expand_dims(mask, axis=0)\n",
        "    y = y/255.0\n",
        "    y = np.expand_dims(y, axis=0)\n",
        "    y = y.astype(np.float32)\n",
        "    y = torch.from_numpy(y)\n",
        "    y = y.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        start_time = time.time()\n",
        "        pred_y = model(x)\n",
        "        pred_y = torch.sigmoid(pred_y)\n",
        "        total_time = time.time() - start_time\n",
        "        time_taken.append(total_time)\n",
        "\n",
        "\n",
        "        score = calculate_metrics(y, pred_y)\n",
        "        metrics_score = list(map(add, metrics_score, score))\n",
        "        pred_y = pred_y[0].cpu().numpy()        ## (1, 512, 512)\n",
        "        pred_y = np.squeeze(pred_y, axis=0)     ## (512, 512)\n",
        "        pred_y = pred_y > 0.5\n",
        "        pred_y = np.array(pred_y, dtype=np.uint8)\n",
        "\n",
        "    ori_mask = mask_parse(mask)\n",
        "    pred_y = mask_parse(pred_y)\n",
        "    line = np.ones((size[1], 10, 3)) * 128\n",
        "\n",
        "    cat_images = np.concatenate(\n",
        "        [cv2.resize(cv2.imread(img, cv2.IMREAD_COLOR), size), line, ori_mask, line, pred_y * 255], axis=1\n",
        "    )\n",
        "    cv2.imwrite(f\"results/{name}.png\", cat_images)\n",
        "\n",
        "jaccard = metrics_score[0]/len(test_x)\n",
        "f1 = metrics_score[1]/len(test_x)\n",
        "recall = metrics_score[2]/len(test_x)\n",
        "precision = metrics_score[3]/len(test_x)\n",
        "acc = metrics_score[4]/len(test_x)\n",
        "roc_auc = metrics_score[5]/len(test_x)\n",
        "print(f\"Jaccard: {jaccard:1.4f} - F1: {f1:1.4f} - Recall: {recall:1.4f} - Precision: {precision:1.4f} - Acc: {acc:1.4f} - ROC-AUC: {roc_auc:1.4f}\")\n",
        "\n",
        "fps = 1/np.mean(time_taken)\n",
        "print(\"FPS: \", fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrpRbF9gj7Di"
      },
      "outputs": [],
      "source": [
        "#!zip -r results.zip results/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvtUasdwvJaY"
      },
      "outputs": [],
      "source": [
        "cv2.imread(img, cv2.IMREAD_COLOR).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_ESgANLVsMD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(epochs), loss_dict['train'])\n",
        "plt.plot(range(epochs), loss_dict['val'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_gaKKYygT5V"
      },
      "outputs": [],
      "source": [
        "image"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
